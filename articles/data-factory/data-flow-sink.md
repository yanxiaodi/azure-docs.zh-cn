---
title: 在 Azure 数据工厂的映射数据流功能中设置接收器转换
description: 了解如何在映射数据流中设置接收器转换。
author: kromerm
ms.author: makromer
ms.service: data-factory
ms.topic: conceptual
ms.date: 02/03/2019
ms.openlocfilehash: 24ad0f2e917420c327577851cabc9e5bdbad2825
ms.sourcegitcommit: 0e59368513a495af0a93a5b8855fd65ef1c44aac
ms.translationtype: MT
ms.contentlocale: zh-CN
ms.lasthandoff: 08/15/2019
ms.locfileid: "69515671"
---
# <a name="sink-transformation-for-a-data-flow"></a>数据流的接收器转换

[!INCLUDE [notes](../../includes/data-factory-data-flow-preview.md)]

转换数据流后, 可以将数据接收到目标数据集。 在接收器转换中, 选择目标输出数据的数据集定义。 您可以根据数据流需要任意数量的接收器转换。

若要考虑架构偏移和传入数据的更改, 请将输出数据接收到输出数据集中没有定义的架构的文件夹。 还可以通过选择源中的 "**允许架构偏移**" 来考虑源中的列更改。 然后自动映射接收器中的所有字段。

!["接收器" 选项卡上的选项, 包括自动映射选项](media/data-flow/sink1.png "接收器 1")

若要接收所有传入字段, 请打开**自动地图**。 若要选择要接收到目标的字段, 或要更改目标中字段的名称, 请关闭 "**自动映射**"。 然后打开 "**映射**" 选项卡以映射输出字段。

!["映射" 选项卡上的选项](media/data-flow/sink2.png "接收器 2")

## <a name="output"></a>Output 
对于 Azure Blob 存储或 Data Lake Storage 接收器类型, 将转换后的数据输出到文件夹中。 Spark 根据接收器转换使用的分区方案生成已分区的输出数据文件。 

可以从 "**优化**" 选项卡设置分区方案。如果希望数据工厂将输出合并到单个文件中, 请选择 "**单一分区**"。

!["优化" 选项卡上的选项](media/data-flow/opt001.png "接收器选项")

## <a name="field-mapping"></a>字段映射
在接收器转换的 "**映射**" 选项卡上, 您可以将左侧的传入列映射到右侧的目标。 将数据流接收到文件时, 数据工厂将始终向文件夹写入新文件。 映射到数据库数据集时, 将选择要插入、更新、upsert 或删除的 "数据库表操作" 选项。

!["映射" 选项卡](media/data-flow/sink2.png "接收器")

在映射表中, 您可以将多个列链接到多个列, 解除链接陈旧多个列, 或者将多个行映射到相同的列名称。

若要始终将传入字段集映射到目标并完全接受灵活的架构定义, 请选择 "**允许架构偏移**"。

!["映射" 选项卡, 显示映射到数据集中的列的字段](media/data-flow/multi1.png "多个选项")

若要重置列映射, 请选择 "**重新映射**"。

![接收器选项卡](media/data-flow/sink1.png "接收一个")

如果架构发生更改, 请选择 "**验证架构**" 以使接收器失败。

选择**清除该文件夹**以截断接收器文件夹的内容, 然后再在该目标文件夹中写入目标文件。

## <a name="rule-based-mapping"></a>基于规则的映射
当关闭自动映射时, 可以选择添加基于列的映射 (固定映射) 或基于规则的映射。 基于规则的映射将允许你编写具有模式匹配的表达式。 

![基于规则的映射](media/data-flow/rules4.png "基于规则的映射")

当你选择 "基于规则的映射" 时, 将指示 ADF 评估匹配的表达式, 以匹配传入模式规则并定义传出字段名称。 可以添加基于字段和基于规则的映射的任意组合。 然后, 在运行时, 将基于源传入的元数据在运行时生成字段名称。 在调试过程中, 可以使用 "数据预览" 窗格查看生成的字段的名称。

有关模式匹配的详细信息位于[列模式文档](concepts-data-flow-column-pattern.md)中。

## <a name="file-name-options"></a>文件名选项

设置文件命名: 

   * **默认**：允许 Spark 基于部分默认值命名文件。
   * **模式**:输入输出文件的模式。 例如,**贷款 [n]** 将创建 loans1、loans2, 依此类推。
   * **每个分区**:每个分区输入一个文件名。
   * **作为列中的数据**:将输出文件设置为列的值。
   * **输出到单个文件**:使用此选项时, ADF 会将已分区的输出文件合并为单个命名文件。 若要使用此选项, 你的数据集应解析为文件夹名称。 另外, 请注意, 根据节点大小, 此合并操作可能会失败。

> [!NOTE]
> 仅当你运行 "执行数据流" 活动时, 文件操作才开始。 它们不会在数据流调试模式下启动。

## <a name="database-options"></a>数据库选项

选择数据库设置:

![显示 SQL 接收器选项的 "设置" 选项卡](media/data-flow/alter-row2.png "SQL 选项")

* **更新方法**:默认为允许插入。 如果要停止从源插入新行, 请清除 "**允许插入**"。 若要更新、upsert 或删除行, 请首先添加一个更改行转换, 以标记这些操作的行。 
* **重新创建表**:请在数据流结束之前删除或创建目标表。
* **截断表**:在数据流完成之前, 从目标表中删除所有行。
* **批大小**：输入一个数字以将写入内容装桶成区块。 对于大型数据加载, 请使用此选项。 
* **启用暂存**:在将 Azure 数据仓库作为接收器数据集加载时使用 PolyBase。
* **Pre 和 POST SQL 脚本**:输入将在写入接收器数据库之前 (预处理) 和之后 (后处理) 数据执行的多行 SQL 脚本

![pre 和 POST SQL 处理脚本](media/data-flow/prepost1.png "SQL 处理脚本")

> [!NOTE]
> 在 "数据流" 中, 可以将数据工厂定向到在目标数据库中创建新的表定义。 若要创建表定义, 请在接收器转换中设置具有新表名称的数据集。 在 SQL 数据集的表名称下方, 选择 "**编辑**", 然后输入新的表名称。 然后, 在接收器转换中启用 "**允许架构偏移**"。 将 "**导入架构**" 设置为 "**无**"。

![SQL 数据集设置, 显示在何处编辑表名称](media/data-flow/dataset2.png "SQL 架构")

> [!NOTE]
> 在数据库接收器中更新或删除行时, 必须设置键列。 此设置允许更改行转换来确定数据移动库 (DML) 中的唯一行。

## <a name="next-steps"></a>后续步骤
创建数据流后, 请将数据流[活动添加到管道](concepts-data-flow-overview.md)。
